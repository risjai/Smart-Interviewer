{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', encoding='iso-8859-1')\n",
    "df = pd.get_dummies(data=df, columns=['InterviewerId', 'Interviewee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the text columns\n",
    "df = df.drop(['Desc_A','Desc_B'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = df.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 6 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    meanAccuracyScore = 0.0\n",
    "    \n",
    "    for i, (train_index, valid_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_va = x_train[valid_index]\n",
    "        y_va = y_train[valid_index]\n",
    "        \n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[valid_index] = clf.predict(x_va)\n",
    "        print(clf.predict_proba(x_va))\n",
    "        accuracy = accuracy_score(y_va, oof_train[valid_index])\n",
    "        #print(accuracy)\n",
    "        meanAccuracyScore = meanAccuracyScore + accuracy\n",
    "\n",
    "    print(\"Accuracy Score\", meanAccuracyScore / 6)\n",
    "    #oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees\n",
      "[[0.56706667 0.43293333]]\n",
      "[[0.34773333 0.65226667]]\n",
      "[[0.43106667 0.56893333]]\n",
      "[[0.35453333 0.64546667]]\n",
      "[[0.64733333 0.35266667]]\n",
      "[[0.6832 0.3168]]\n",
      "Accuracy Score 1.0\n",
      "Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sumo\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\ensemble\\forest.py:305: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3662 0.6338]]\n",
      "[[0.29353333 0.70646667]]\n",
      "[[0.33153333 0.66846667]]\n",
      "[[0.28486667 0.71513333]]\n",
      "[[0.4742 0.5258]]\n",
      "[[0.4942 0.5058]]\n",
      "Accuracy Score 0.5\n",
      "Ada boost\n",
      "[[2.22044605e-16 1.00000000e+00]]\n",
      "[[2.22044605e-16 1.00000000e+00]]\n",
      "[[2.22044605e-16 1.00000000e+00]]\n",
      "[[2.22044605e-16 1.00000000e+00]]\n",
      "[[1.00000000e+00 2.22044605e-16]]\n",
      "[[1.00000000e+00 2.22044605e-16]]\n",
      "Accuracy Score 0.8333333333333334\n",
      "Gradient Boost\n",
      "[[0.0897737 0.9102263]]\n",
      "[[3.53447937e-04 9.99646552e-01]]\n",
      "[[0.01019715 0.98980285]]\n",
      "[[3.53447937e-04 9.99646552e-01]]\n",
      "[[9.99646552e-01 3.53447937e-04]]\n",
      "[[9.99646552e-01 3.53447937e-04]]\n",
      "Accuracy Score 0.8333333333333334\n",
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "y_train = df['Hire_call_interviewer_1'].ravel()\n",
    "train = df.drop(['Hire_call_interviewer_1'], axis=1)\n",
    "x_train = df.values # Creates an array of the train data\n",
    "\n",
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "print(\"Extra Trees\")\n",
    "et_oof_train = get_oof(et, x_train, y_train) # Extra Trees\n",
    "print(\"Random Forest\")\n",
    "rf_oof_train = get_oof(rf,x_train, y_train) # Random Forest\n",
    "print(\"Ada boost\")\n",
    "ada_oof_train = get_oof(ada, x_train, y_train) # AdaBoost \n",
    "print(\"Gradient Boost\")\n",
    "gb_oof_train = get_oof(gb,x_train, y_train) # Gradient Boost\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "forest = ExtraTreesClassifier(n_estimators=250, random_state=0)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"extra_trees.pickle\", \"wb\")\n",
    "pickle.dump(forest, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"extra_trees.pickle\", \"rb\")\n",
    "classifier = pickle.load(pickle_in)\n",
    "classifier.predict_proba(x_train[1].reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
